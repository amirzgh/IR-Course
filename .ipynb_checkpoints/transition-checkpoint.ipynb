{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "path_direction = \"resources/transition-data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 19/19 [00:00<00:00, 184471.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import tqdm\n",
    "\n",
    "datas = [x.strip() for x in tqdm.tqdm(codecs.open(F'{path_direction}','rU','utf-8').readlines())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['علی به مدرسه رفت.', 'ما با پیکان جوانان گوجه ای به مشهَدالرضا رفتیم.', 'محمد و دوستش با تیبا از مهاباد به شیراز سفر کردند.', 'فاطمه با ماشین به یزد آمد.', 'اتوبوس به تهران رسید.', 'علی به مقصد اهواز حرکت کرد.', 'خوانواده هاشمی با اتوبوس از نیشایور به قم رفتند.', 'محمد رضا با پراید از ماهشهر به تهران رفت.', 'دوستان من برای اردو به شیراز رفتند.', 'سفر با ماشین به خراسان به پایان رسید.', 'نیسان آبی از ارومیه به تبریز رسید.', 'سفر با هواپیما از تهران به شیراز آسان بود.', 'فردا با پژو به مشهد خواهیم رفت.', 'ما با تاکسی به کرج رفتیم.', 'دوستم با هواپیما به یزد سفر کرد.', 'دوستان من با سمند به کرج رفتند.', 'اتوبوس بازیکنان به رست رسید.', 'مسافران قطار از تهران به مقصد شهر ری سوار شدند.', 'دیروز با هواپیما به تهران آمدم.']\n"
     ]
    }
   ],
   "source": [
    "print(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from hazm import *\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# data_normalized = [[normalizer.normalize(y) for y in x] for x in tqdm.tqdm(datas)]\n",
    "data_normalized = [normalizer.normalize(y) for y in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "علی به مدرسه رفت.\n",
      "ما با پیکان جوانان گوجه‌ای به مشهدالرضا رفتیم.\n",
      "محمد و دوستش با تیبا از مهاباد به شیراز سفر کردند.\n",
      "فاطمه با ماشین به یزد آمد.\n",
      "اتوبوس به تهران رسید.\n",
      "علی به مقصد اهواز حرکت کرد.\n",
      "خوانواده هاشمی با اتوبوس از نیشایور به قم رفتند.\n",
      "محمد رضا با پراید از ماهشهر به تهران رفت.\n",
      "دوستان من برای اردو به شیراز رفتند.\n",
      "سفر با ماشین به خراسان به پایان رسید.\n",
      "نیسان آبی از ارومیه به تبریز رسید.\n",
      "سفر با هواپیما از تهران به شیراز آسان بود.\n",
      "فردا با پژو به مشهد خواهیم رفت.\n",
      "ما با تاکسی به کرج رفتیم.\n",
      "دوستم با هواپیما به یزد سفر کرد.\n",
      "دوستان من با سمند به کرج رفتند.\n",
      "اتوبوس بازیکنان به رست رسید.\n",
      "مسافران قطار از تهران به مقصد شهر ری سوار شدند.\n",
      "دیروز با هواپیما به تهران آمدم.\n"
     ]
    }
   ],
   "source": [
    "for x in data_normalized :\n",
    "    print(''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 19/19 [00:00<00:00, 53484.41it/s]\n"
     ]
    }
   ],
   "source": [
    "data_sentences = [sent_tokenize(''.join(x)) for x in tqdm.tqdm(data_normalized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "علی به مدرسه رفت.\n",
      "ما با پیکان جوانان گوجه ای به مشهدالرضا رفتیم.\n",
      "محمد و دوستش با تیبا از مهاباد به شیراز سفر کردند.\n",
      "فاطمه با ماشین به یزد آمد.\n",
      "اتوبوس به تهران رسید.\n",
      "علی به مقصد اهواز حرکت کرد.\n",
      "خوانواده هاشمی با اتوبوس از نیشایور به قم رفتند.\n",
      "محمد رضا با پراید از ماهشهر به تهران رفت.\n",
      "دوستان من برای اردو به شیراز رفتند.\n",
      "سفر با ماشین به خراسان به پایان رسید.\n",
      "نیسان آبی از ارومیه به تبریز رسید.\n",
      "سفر با هواپیما از تهران به شیراز آسان بود.\n",
      "فردا با پژو به مشهد خواهیم رفت.\n",
      "ما با تاکسی به کرج رفتیم.\n",
      "دوستم با هواپیما به یزد سفر کرد.\n",
      "دوستان من با سمند به کرج رفتند.\n",
      "اتوبوس بازیکنان به رست رسید.\n",
      "مسافران قطار از تهران به مقصد شهر ری سوار شدند.\n",
      "دیروز با هواپیما به تهران آمدم.\n"
     ]
    }
   ],
   "source": [
    "for x in data_sentences:\n",
    "    print('###'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 19/19 [00:00<00:00, 94.69it/s]\n"
     ]
    }
   ],
   "source": [
    "data_tokens = [[word_tokenize(sentence) for sentence in sentences] for sentences in tqdm.tqdm(data_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['علی', 'به', 'مدرسه', 'رفت', '.']],\n",
       " [['ما',\n",
       "   'با',\n",
       "   'پیکان',\n",
       "   'جوانان',\n",
       "   'گوجه',\n",
       "   'ای',\n",
       "   'به',\n",
       "   'مشهدالرضا',\n",
       "   'رفتیم',\n",
       "   '.']],\n",
       " [['محمد',\n",
       "   'و',\n",
       "   'دوستش',\n",
       "   'با',\n",
       "   'تیبا',\n",
       "   'از',\n",
       "   'مهاباد',\n",
       "   'به',\n",
       "   'شیراز',\n",
       "   'سفر',\n",
       "   'کردند',\n",
       "   '.']],\n",
       " [['فاطمه', 'با', 'ماشین', 'به', 'یزد', 'آمد', '.']],\n",
       " [['اتوبوس', 'به', 'تهران', 'رسید', '.']],\n",
       " [['علی', 'به', 'مقصد', 'اهواز', 'حرکت', 'کرد', '.']],\n",
       " [['خوانواده',\n",
       "   'هاشمی',\n",
       "   'با',\n",
       "   'اتوبوس',\n",
       "   'از',\n",
       "   'نیشایور',\n",
       "   'به',\n",
       "   'قم',\n",
       "   'رفتند',\n",
       "   '.']],\n",
       " [['محمد', 'رضا', 'با', 'پراید', 'از', 'ماهشهر', 'به', 'تهران', 'رفت', '.']],\n",
       " [['دوستان', 'من', 'برای', 'اردو', 'به', 'شیراز', 'رفتند', '.']],\n",
       " [['سفر', 'با', 'ماشین', 'به', 'خراسان', 'به', 'پایان', 'رسید', '.']],\n",
       " [['نیسان', 'آبی', 'از', 'ارومیه', 'به', 'تبریز', 'رسید', '.']],\n",
       " [['سفر', 'با', 'هواپیما', 'از', 'تهران', 'به', 'شیراز', 'آسان', 'بود', '.']],\n",
       " [['فردا', 'با', 'پژو', 'به', 'مشهد', 'خواهیم_رفت', '.']],\n",
       " [['ما', 'با', 'تاکسی', 'به', 'کرج', 'رفتیم', '.']],\n",
       " [['دوستم', 'با', 'هواپیما', 'به', 'یزد', 'سفر', 'کرد', '.']],\n",
       " [['دوستان', 'من', 'با', 'سمند', 'به', 'کرج', 'رفتند', '.']],\n",
       " [['اتوبوس', 'بازیکنان', 'به', 'رست', 'رسید', '.']],\n",
       " [['مسافران',\n",
       "   'قطار',\n",
       "   'از',\n",
       "   'تهران',\n",
       "   'به',\n",
       "   'مقصد',\n",
       "   'شهر',\n",
       "   'ری',\n",
       "   'سوار',\n",
       "   'شدند',\n",
       "   '.']],\n",
       " [['دیروز', 'با', 'هواپیما', 'به', 'تهران', 'آمدم', '.']]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_database(file_path):\n",
    "    file = open(file_path, \"r\")\n",
    "    return file.read()\n",
    "\n",
    "def read_list_from_file(file_path):\n",
    "    lst = read_database(file_path)\n",
    "    lst = lst.strip('][').split(', ')\n",
    "    lst = lst[0].replace(\"\\\"\", \"\").replace(\",\", \"\").replace(\" \", \"\").split(\"\\n\")\n",
    "    final_list = []\n",
    "    for string in lst:\n",
    "        if (string != \"\"):\n",
    "            final_list.append(string)\n",
    "    return final_list\n",
    "        \n",
    "cars = read_list_from_file(\"database/cars.txt\")\n",
    "vehicles = read_list_from_file(\"database/vehicle.txt\")\n",
    "vehicles = cars + vehicles\n",
    "#########\n",
    "countries = read_list_from_file(\"database/countries.txt\")\n",
    "address_keyword = read_list_from_file(\"database/address keyword.txt\")\n",
    "provincies = read_list_from_file(\"database/provincies.txt\")\n",
    "places = read_list_from_file(\"database/places.txt\")\n",
    "places = countries + address_keyword + provincies + places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "علی به مدرسه رفت.\n",
      "ما با پیکان جوانان گوجه ای به مشهَدالرضا رفتیم.\n",
      "محمد و دوستش با تیبا از مهاباد به شیراز سفر کردند.\n",
      "فاطمه با ماشین به یزد آمد.\n",
      "اتوبوس به تهران رسید.\n",
      "علی به مقصد اهواز حرکت کرد.\n",
      "خوانواده هاشمی با اتوبوس از نیشایور به قم رفتند.\n",
      "محمد رضا با پراید از ماهشهر به تهران رفت.\n",
      "دوستان من برای اردو به شیراز رفتند.\n",
      "سفر با ماشین به خراسان به پایان رسید.\n",
      "نیسان آبی از ارومیه به تبریز رسید.\n",
      "سفر با هواپیما از تهران به شیراز آسان بود.\n",
      "فردا با پژو به مشهد خواهیم رفت.\n",
      "ما با تاکسی به کرج رفتیم.\n",
      "دوستم با هواپیما به یزد سفر کرد.\n",
      "دوستان من با سمند به کرج رفتند.\n",
      "اتوبوس بازیکنان به رست رسید.\n",
      "مسافران قطار از تهران به مقصد شهر ری سوار شدند.\n",
      "دیروز با هواپیما به تهران آمدم.\n",
      "[{'to': 'مدرسه'}, {'to': 'مدرسه'}, {'to': 'مدرسه'}, {'to': 'مدرسه'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'پیکان'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'تیبا'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'to': 'تهران'}, {'to': 'تهران'}, {'to': 'تهران'}, {'to': 'تهران'}, {}, {}, {}, {}, {}, {}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'اتوبوس', 'to': 'قم'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {'vehicle': 'پراید', 'to': 'تهران'}, {}, {}, {}, {}, {}, {}, {}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {'vehicle': 'ماشین'}, {}, {}, {}, {}, {}, {}, {}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'هواپیما', 'from': 'تهران'}, {'vehicle': 'پژو'}, {'vehicle': 'پژو'}, {'vehicle': 'پژو'}, {'vehicle': 'پژو'}, {'vehicle': 'پژو'}, {'vehicle': 'پژو'}, {'vehicle': 'تاکسی'}, {'vehicle': 'تاکسی'}, {'vehicle': 'تاکسی'}, {'vehicle': 'تاکسی'}, {'vehicle': 'تاکسی'}, {'vehicle': 'تاکسی'}, {'vehicle': 'هواپیما'}, {'vehicle': 'هواپیما'}, {'vehicle': 'هواپیما'}, {'vehicle': 'هواپیما'}, {'vehicle': 'هواپیما'}, {'vehicle': 'هواپیما'}, {'vehicle': 'هواپیما'}, {'vehicle': 'سمند'}, {'vehicle': 'سمند'}, {'vehicle': 'سمند'}, {'vehicle': 'سمند'}, {'vehicle': 'سمند'}, {'vehicle': 'سمند'}, {'vehicle': 'سمند'}, {}, {}, {}, {}, {}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'from': 'تهران'}, {'vehicle': 'هواپیما', 'to': 'تهران'}, {'vehicle': 'هواپیما', 'to': 'تهران'}, {'vehicle': 'هواپیما', 'to': 'تهران'}, {'vehicle': 'هواپیما', 'to': 'تهران'}, {'vehicle': 'هواپیما', 'to': 'تهران'}, {'vehicle': 'هواپیما', 'to': 'تهران'}]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(data_tokens)):\n",
    "    sentence = data_tokens[j]\n",
    "    sentence_full = datas[j]\n",
    "    print(sentence_full)\n",
    "    sentence = sentence[0]\n",
    "    res_dict = {}\n",
    "    for i in range(len(sentence)-1):\n",
    "        if sentence[i] == \"از\":\n",
    "            if sentence[i+1] in places:\n",
    "                res_dict[\"from\"] = sentence[i+1]\n",
    "        if sentence[i] == \"به\":\n",
    "            if sentence[i+1] in places:\n",
    "                res_dict[\"to\"] = sentence[i+1]\n",
    "        if sentence[i] == \"با\":\n",
    "            if sentence[i+1] in vehicles:\n",
    "                res_dict[\"vehicle\"] = sentence[i+1]\n",
    "        result.append(res_dict)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "all_tokens = list(itertools.chain(*itertools.chain(*data_tokens)))\n",
    "\n",
    "dataframe = {}\n",
    "\n",
    "for opt in ['all']:\n",
    "    dataframe[opt] = FreqDist(eval(F\"{opt}_tokens\")).most_common(10)\n",
    "\n",
    "freq_anlyst = pd.DataFrame(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(به, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(., 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(با, 12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(از, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(تهران, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(سفر, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(رسید, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(شیراز, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(اتوبوس, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(رفتند, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           all\n",
       "0     (به, 20)\n",
       "1      (., 19)\n",
       "2     (با, 12)\n",
       "3      (از, 6)\n",
       "4   (تهران, 5)\n",
       "5     (سفر, 4)\n",
       "6    (رسید, 4)\n",
       "7   (شیراز, 3)\n",
       "8  (اتوبوس, 3)\n",
       "9   (رفتند, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_anlyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words  155             \n",
      "Number of unique words 72              \n",
      "Average word length 3.432258064516129\n",
      "Longest word     خواهیم_رفت      \n"
     ]
    }
   ],
   "source": [
    "print ('%-16s' % 'Number of words', '%-16s' % len(all_tokens))\n",
    "print ('%-16s' % 'Number of unique words', '%-16s' % len(set(all_tokens)))\n",
    "avg=np.sum([len(word) for word in all_tokens])/len(all_tokens)\n",
    "print ('%-16s' % 'Average word length', '%-16s' % avg)\n",
    "print ('%-16s' % 'Longest word', '%-16s' % all_tokens[np.argmax([len(word) for word in all_tokens])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = [normalizer.normalize(x.strip()) for x in codecs.open('resources/stopwords.txt','r','utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:00<00:00, 70199.45it/s]\n"
     ]
    }
   ],
   "source": [
    "all_tokens_nonstop = [t for t in tqdm.tqdm(all_tokens) if t not in stopwords]\n",
    "\n",
    "dataframe_nonstop = {}\n",
    "\n",
    "for opt in ['all']:\n",
    "     dataframe_nonstop[opt] = FreqDist(eval(F\"{opt}_tokens_nonstop\")).most_common(30)\n",
    "\n",
    "freq_analysis_nonstop = pd.DataFrame(dataframe_nonstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(., 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(تهران, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(سفر, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(شیراز, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(اتوبوس, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(رفتند, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(هواپیما, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(علی, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(رفتیم, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(محمد, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(ماشین, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(یزد, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(مقصد, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(دوستان, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(کرج, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(مدرسه, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(پیکان, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(جوانان, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(گوجه, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(ای, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(مشهدالرضا, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(دوستش, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(تیبا, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(مهاباد, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(فاطمه, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(اهواز, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(حرکت, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(خوانواده, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(هاشمی, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(نیشایور, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               all\n",
       "0          (., 19)\n",
       "1       (تهران, 5)\n",
       "2         (سفر, 4)\n",
       "3       (شیراز, 3)\n",
       "4      (اتوبوس, 3)\n",
       "5       (رفتند, 3)\n",
       "6     (هواپیما, 3)\n",
       "7         (علی, 2)\n",
       "8       (رفتیم, 2)\n",
       "9        (محمد, 2)\n",
       "10      (ماشین, 2)\n",
       "11        (یزد, 2)\n",
       "12       (مقصد, 2)\n",
       "13     (دوستان, 2)\n",
       "14        (کرج, 2)\n",
       "15      (مدرسه, 1)\n",
       "16      (پیکان, 1)\n",
       "17     (جوانان, 1)\n",
       "18       (گوجه, 1)\n",
       "19         (ای, 1)\n",
       "20  (مشهدالرضا, 1)\n",
       "21      (دوستش, 1)\n",
       "22       (تیبا, 1)\n",
       "23     (مهاباد, 1)\n",
       "24      (فاطمه, 1)\n",
       "25      (اهواز, 1)\n",
       "26       (حرکت, 1)\n",
       "27   (خوانواده, 1)\n",
       "28      (هاشمی, 1)\n",
       "29    (نیشایور, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_analysis_nonstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def get_lemma_set(token,opt=1):\n",
    "    if opt == 1 :\n",
    "        return stemmer.stem(token)\n",
    "    elif opt ==2 :\n",
    "        return lemmatizer.lemmatize(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 100492.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(., 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(رفت#رو, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(تهران, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(سفر, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(شیراز, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(اتوبوس, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(هواپیما, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(علی, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(محمد, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ماشین, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(یزد, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(مقصد, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(دوستان, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(کرج, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(مدرسه, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(پیکان, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(جوان, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(گوجه, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(ای, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(مشهدالرضا, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(دوست, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(تیبا, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(مهاباد, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(فاطمه, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(اهواز, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(حرکت, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(خوانواده, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(هاشم, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(نیشایور, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(قم, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              stem\n",
       "0          (., 19)\n",
       "1      (رفت#رو, 6)\n",
       "2       (تهران, 5)\n",
       "3         (سفر, 4)\n",
       "4       (شیراز, 3)\n",
       "5      (اتوبوس, 3)\n",
       "6     (هواپیما, 3)\n",
       "7         (علی, 2)\n",
       "8        (محمد, 2)\n",
       "9       (ماشین, 2)\n",
       "10        (یزد, 2)\n",
       "11       (مقصد, 2)\n",
       "12     (دوستان, 2)\n",
       "13        (کرج, 2)\n",
       "14      (مدرسه, 1)\n",
       "15      (پیکان, 1)\n",
       "16       (جوان, 1)\n",
       "17       (گوجه, 1)\n",
       "18         (ای, 1)\n",
       "19  (مشهدالرضا, 1)\n",
       "20       (دوست, 1)\n",
       "21       (تیبا, 1)\n",
       "22     (مهاباد, 1)\n",
       "23      (فاطمه, 1)\n",
       "24      (اهواز, 1)\n",
       "25       (حرکت, 1)\n",
       "26   (خوانواده, 1)\n",
       "27       (هاشم, 1)\n",
       "28    (نیشایور, 1)\n",
       "29         (قم, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = 2\n",
    "\n",
    "all_tokens_nonstop_stem = [get_lemma_set(t, opt) for t in tqdm.tqdm(all_tokens_nonstop)]\n",
    "\n",
    "dataframe_nonstop_stem = {}\n",
    "\n",
    "for opt in ['stem']:\n",
    "     dataframe_nonstop_stem[opt] = FreqDist(eval(\"all_tokens_nonstop_stem\")).most_common(30)\n",
    "\n",
    "freq_analysis_nonstop_stem = pd.DataFrame(dataframe_nonstop_stem)\n",
    "freq_analysis_nonstop_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwapiti\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      2\u001b[0m tagger \u001b[38;5;241m=\u001b[39m POSTagger(model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresources/postagger.model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "from wapiti import Model\n",
    "tagger = POSTagger(model = 'resources/postagger.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tagger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m selected\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m FreqDist(\u001b[38;5;28meval\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_tokens_nonstop_stem\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43mtagger\u001b[49m\u001b[38;5;241m.\u001b[39mtag([x])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      8\u001b[0m         selected\u001b[38;5;241m.\u001b[39mappend((x,y))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tagger' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "dataframe_nonstop_stem_advjj = {}\n",
    "\n",
    "selected=[]\n",
    "for x,y in FreqDist(eval(\"all_tokens_nonstop_stem\")).most_common(30):\n",
    "    pos = tagger.tag([x])[0][1]\n",
    "    if pos in ['adj']:\n",
    "        selected.append((x,y))\n",
    "dataframe_nonstop_stem_advjj = copy.deepcopy(selected[0:40])\n",
    "dataframe_nonstop_stem_advjj = pd.DataFrame(dataframe_nonstop_stem_advjj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_nonstop_stem_advjj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
